name: "Safe Explorer"
help: 'Pytorch implementation of "Safe Exploration in Continuous Action Spaces".'
arguments:
  - name: "env"
    help: "Configuration related to simulation environments."
    properties:
      - name: "spaceship"
        help: "Spaceship environment configuration."
        properties:
          - name: "length"
            default: 2.5
          - name: "margin"
            default: 0.2
          - name: "agent_slack"
            default: 0.05
          - name: "frequency_ratio"
            default: 0.1
          - name: "target_noise_std"
            default: 0.05
          - name: "target_radius"
            default: 0.05
          - name: "corridor_episode_length"
            default: 15
          - name: "arena_episode_length"
            default: 45
          - name: "enable_reward_shaping"
            default: false
          - name: "is_arena"
            default: true
          - name: "reward_shaping_slack"
            default: 0.1
      - name: "ballnd"
        help: "Ball-ND environment configuration."
        properties:
          - name: "n"
            default: 1
          - name: "target_margin"
            default: 0.2
          - name: "agent_slack"
            default: 0.05
          - name: "episode_length"
            default: 30
          - name: "frequency_ratio"
            default: 0.1
          - name: "respawn_interval"
            default: 0.5
          - name: "target_noise_std"
            default: 0.05
          - name: "enable_reward_shaping"
            default: false
          - name: "reward_shaping_slack"
            default: 0.1          
  - name: "ddpg"
    help: "Hyperparameters for DDPG algorithm."
    properties:
    - name: "actor"
      help: "Actor network parameters."
      properties:
        - name: "layers"
          default: [356, 128]   # default: [128, 64]
        - name: "init_bound"
          default: 0.003
    - name: "critic"
      help: "Critic network parameters."
      properties:
        - name: "layers"
          default: [356, 128, 32]  #default: [64, 128, 32]
        - name: "init_bound"
          default: 0.003
    - name: "trainer"
      help: "Training parameters."
      properties:
        - name: "epochs"
          default: 20000  #800
        - name: "steps_per_epoch"
          default: 24 #1200
        - name: "evaluation_steps"
          default: 24
        - name: "batch_size"
          default: 64   #512
        - name: "max_episode_length"
          default: 25
        - name: "replay_buffer_size"
          default: 500000   #10000000
        - name: "discount_factor"
          default: 0.95 #0.99
        - name: "polyak"
          default: 0.995
        - name: "actor_lr"
          default: 0.0003    #0.0001
        - name: "critic_lr"
          default: 0.0003    #0.0001
        - name: "start_steps"
          default: 500  #500
        - name: "action_noise_range"
          default: 0.05   #0.01
        - name: "use_gpu"
          default: false
        - name: "reward_scale"
          default: 1
        - name: "max_updates_per_episode"
          default: 8
        - name: "min_buffer_fill"
          default: 20000  #def: 200
  - name: "main"
    help: "Safe-Explorer driver properties."
    properties:
      - name: "trainer"
        help: "Training configuration."
        properties:
          - name: "seed"
            default: 0